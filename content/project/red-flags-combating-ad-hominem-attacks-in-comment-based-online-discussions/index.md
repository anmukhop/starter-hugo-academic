---
title: "Red Flags: Combating ad hominem attacks in comment-based online discussions"
date: 2021-12-08T05:52:40.081Z
summary: >-
  Computer Supported Collaborative Work Course project.


  Here we propose a flagging mechanism that modifies the process of reporting currently found in popular platforms like Facebook, Instagram, and Twitter. We describe the design, development, and evaluation of a method of curbing ad hominem attacks that occur in common online discussion spaces, particularly comments and replies to posts. Through ethnographic interviews as well as a small-scale user study, we explore the emotional experiences of being the target of or witnessing trolling online, revealing the needs of these groups in these interactions.
draft: false
featured: false
authors:
  - Anirban Mukhopadhyay
  - Juliet Clarke
  - Liling Yuan
tags:
  - Combat online trolling
  - Qualitative study
  - Prototyping
links:
  - url: https://drive.google.com/file/d/1AXnHOafj2iRrwptBtx_ZBdy0L4b8fewf/view?usp=sharing
    name: Project paper link
image:
  filename: featured.png
  focal_point: Smart
  preview_only: false
  caption: The curated social media feed for user study
---
Trolling in social media has become a serious social issue. In this study, we aim to understand the needs of social media users who have experienced and witnessed trolling. Based on ethnographic interviews, we found that victims feel isolated and hurt among other psychological effects due to ad hominem attacks during online discourse. In order to address the issue, we propose a flagging mechanism that modifies the process of reporting currently found in popular platforms like Facebook, Instagram, and Twitter. The feature combats trolling through collaboration and by allowing bystanders and content creators to provide feedback that can help develop a shared understanding of community guidelines. We develop a prototype and perform user studies to evaluate the flagging feature. Semi-structured interviews combined with a small-scale user study establish that the proposed UI control on comment threads is able to make users feel supported when they encounter problematic content on the prototype platform.